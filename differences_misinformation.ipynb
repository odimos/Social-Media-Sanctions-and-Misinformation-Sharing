{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Media Sanctions and Misinformation Sharing\n",
    "\n",
    "There has been a lot of discussions on politics and sanctions in social media. Specifically, people with conservative beliefs argue that they are more likely to be sanctioned on social media than those with more liberal beliefs.\n",
    "\n",
    "If this happens, however, that may not necessarily be the result of different policies on behalf of the social media companies. It may simply be that people with conservative beliefs post online more questionable content, and so they are more likely to be sanctioned even with a completely neutral sanction policy.\n",
    "\n",
    "In a [recent analysis in Nature](https://www.nature.com/articles/s41586-024-07942-8), Mohshen Moshel et al. investigated whether social media sanctions are politically biased or they are the result of differences in misinformation sharing between people of different political beliefs. The authors argue that that media sanctions are not politically biased. Social media users with conservative political beliefs are more likely to post questionable or misinformation material, and so they are more likely to be sanctioned. In this assignment, you will follow through some of Moshel et al.'s research.\n",
    "\n",
    "You will use their data, available at [mosleh_et_al_data.csv](mosleh_et_al_data.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Suspensions after the 2020 Election\n",
    "\n",
    "Show, using crosstabulation, that accounts that shared `#Trump2020` during the election were about 4.4 times more likely to be subsequently suspended than the accounts that shared `#VoteBidenHarris2020` (relevant columns: `politics_hashtag` and `suspended`). Then perform a $\\chi^2$ test on the contingency table and explain the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions of Relative Frequency of Low Quality\n",
    "\n",
    "Plot the distributions of low-quality sharing as determined by eight professional fact-checkers (column `lowqual_pr2019_fc`), grouped by `politics_hashtag`. The $x$-axis should be standardized using z-scores. The distributions should look like the following figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig_1.svg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having done, that, proceed to do the same with low-quality sharing as determined by crowdsourcing from 971 participants from the USA (column `lowqual_pr2019_crowd`). The distributions should look like the following figure.\n",
    "\n",
    "<img src=\"fig_2.svg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-quality News Sharing on Twitter\n",
    "\n",
    "We will proceed to examine low-quality news sharing on Twitter on a more quantitave manner, using the t-test. In particular, we will use the t-test based on groups of users depending on their `politics_hashtag` and various assessments of low-quality news sharing. We will quantify the effect size of the t-test using Cohen's $d$ and Hedges' $g$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cohen's $d$ is defined as the difference between two means divided by a standard deviation for the data, i.e.:\n",
    "\n",
    "$$ d = \\frac{\\bar{x}_{1} - \\bar{x}_{2}}{s} $$\n",
    "\n",
    "$s$, the pooled standard deviation for two independent samples is defined as:\n",
    "\n",
    "$$ s=\\sqrt{\\frac{(n_{1}-1)s_{1}^{2}+(n_{2}-1)s_{2}^{2}}{n_{1}+n_{2}-2}} $$\n",
    "\n",
    "where $n_1$, $n_2$ is the size of each sample and the variance of $s_1$ is defined as:\n",
    "\n",
    "$$ s_{1}^{2}=\\frac{1}{n_{1}-1} \\sum _{i=1}^{n_{1}}(x_{1,i}-{\\bar {x}}_{1})^{2} $$\n",
    "\n",
    "with the variance of $s_2$ defined similarly. The values of Cohen's $d$ can be interpreted as follows:\n",
    "\n",
    "| Effect Size | $d$  |\n",
    "|-------------|------|\n",
    "| Very small  | 0.01 |\n",
    "| Small\t      | 0.20 |\n",
    "| Medium\t  | 0.50 |\n",
    "| Large\t      | 0.80 |\n",
    "| Very large  | 1.20 |\n",
    "| Huge        | 2.00 |\n",
    "\n",
    "Hedges' $g$ corrects Cohen's $d$ for bias in small sample sizes and is defined as:\n",
    "\n",
    "$$ \\Bigg(1 - \\frac{3}{4  (n_1 + n_2) - 9)}\\Bigg)d $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will perform a t-test statistic and report Cohen's $d$ and Hedges' $g$ for the following, grouped by `politics_hashtag`.\n",
    "\n",
    "* `lowqual_pr2019_fc` (sites rated by fact-checkers)\n",
    "* `lowqual_afm` (sites rated by Ad Fontes media, <https://adfontesmedia.com/>)\n",
    "* `lowqual_mbfc` (sites rated by Media Bias/Fact Check, <https://mediabiasfactcheck.com/>)\n",
    "* `lowqual_lasser2019` (sites rated by Laser et al., https://doi.org/10.1093/pnasnexus/pgac186)\n",
    "* `lowqual_pr2019_crowd` (sites rated by crowdsourcing 971 participants from the USA)\n",
    "* `lowqual_pr2019_crowdrep` (sites rated by the republicans among the 971 participants of above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharing Lower-quality News Sources and Conservative Ideology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if there is a correlation between lower-quality news sources and conservative ideology, you will perform pairwise correlations between, on the one hand:\n",
    "\n",
    " * `lowqual_pr2019_fc`\n",
    " * `lowqual_lasser2019`\n",
    " * `lowqual_mbfc`\n",
    " * `lowqual_afm`\n",
    " * `lowqual_pr2019_crowd`\n",
    " * `lowqual_pr2019_crowdrep`\n",
    "\n",
    "and on the other hand:\n",
    "\n",
    " * `politics_followed` (political ideology estimated on the basis of Twitter accounts user followed)\n",
    " * `politics_hashtag`\n",
    " * `politics_sites1` (political ideology estimated on the basis of the news sites the users share, <https://doi.org/10.1126/science.aau2706>)\n",
    " * `politics_sites2` (political ideology estimated on the basis of the news sites ther users share, <https://doi.org/10.31219/osf.io/ch8gj>)\n",
    "\n",
    "You should display the results in a heatmap like the following:\n",
    "\n",
    "<img src=\"fig_3.svg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Sharing Can Help Explain Suspension, Using Single Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use the following predictors to predict whether a user was suspended or not:\n",
    "\n",
    "  * `politics_hashtag`\n",
    "  * `politics_sites1`\n",
    "  * `politics_sites2`\n",
    "  * `politics_followed`\n",
    "  * `lowqual_afm`\n",
    "  * `lowqual_mbfc`\n",
    "  * `lowqual_lasser2019`\n",
    "  * `lowqual_pr2019_fc`\n",
    "  * `lowqual_pr2019_crowd`\n",
    "\n",
    "The predictions will be with a probit model. The probit model is an alternative to logit, but while the latter uses the logit as the *link function*, the probit model uses the inverse of the cumulative distribution function (CDF) of the standard normal distribution (denoted as $\\Phi^{-1}$) as the link function. Mathematically:\n",
    "\n",
    "$$ \\Phi^{-1}(P(Y = 1 | X)) = X\\beta $$\n",
    "\n",
    "where $P(Y = 1  | X)$ is the probability of the event occurring, $X$ represents the independent variables, and $\\beta$ is the vector of coefficients.\n",
    "\n",
    "The predictions will be evaluated with the AUC of the ROC curve. To get confidence intervals, repeat each prediction 100 times by using the boostrap method. \n",
    "\n",
    "Print the AUC and the confidence intervals in a table. Then use them to plot all your evaluations and the confidence intervals in a barchart like the following:\n",
    "\n",
    "<img src=\"fig_4.svg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Sharing Can Help Explain Suspension, Using Multiple Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also use multiple regression models to predict and explain suspension. \n",
    "\n",
    "Start by filing in missing values in your data by using the column mean. Then log transform, base 10, the variables that are related to Tweeter metrics, i.e.:\n",
    "\n",
    "* `repeated_tweet_count` to `log_repeated_tweet_count`\n",
    "* `freq_pr_1h` (maximum frequency of primary tweets in an hour) to `log_freq_pr_1h`\n",
    "* `num_followers` to `log_num_followers`\n",
    "* `num_friends` to `log_num_friends`\n",
    "\n",
    "Introduce an additional variable, `log_num_fol`, which should the be base 10 logarithm of `num_friends` over `num_followers` ratio. To prevent out of domain errors, add 1 to each variable when using it in the transforms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the effect of outliers, you will [winsorize](https://en.wikipedia.org/wiki/Winsorizing) the data. Winzorize from both sides at the top 1% the following variables:\n",
    "\n",
    "* `valence_neg`\n",
    "* `valence_neu`\n",
    "* `valence_pos`\n",
    "* `barbera_std`\n",
    "* `politics_sites1_std`\n",
    "* `politics_sites2_ideo_std`\n",
    "\n",
    "The `valence_*`, variables were calculated using VADER (<https://doi.org/10.1609/icwsm.v8i1.14550>). The `barbera_std` variable was calculated based on the work of Barbera et al. (<https://doi.org/10.1177/0956797615594620>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Winsorize the upper side of the following  variables at the top 1%:\n",
    "\n",
    "* `moral_outrage`\n",
    "* `rewire_abuse`\n",
    "* `rewire_hate`\n",
    "* `rewire_profanity`\n",
    "* `rewire_violent`\n",
    "* `rewire_sexually_explicit`\n",
    "* `jigsaw_toxicity`\n",
    "* `jigsaw_severe_toxicity`\n",
    "* `jigsaw_idenity_attack`\n",
    "* `jigsaw_insult`\n",
    "* `jigsaw_profanity`\n",
    "* `jigsaw_threat`\n",
    "\n",
    "The `moral_outrage` variable was calculated based on the work of Brady et al. (<https://doi.org/doi:10.1126/sciadv.abe5641>). The `rewire_*` variables were calculated using the Rewire Online API (acquired by ActiveFence in 2023)., The `jigsaw_*` variables were calculated using the Google Jigsaw Perspective API (<https://jigsaw.google.com/>, <https://perspectiveapi.com/>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will derive and use a single PCA component, `pc1_misinfo`, for low quality news sharing, that is, the variables:\n",
    "\n",
    "* `lowqual_pr2019_fc`\n",
    "* `lowqual_afm`\n",
    "* `lowqual_lasser2019`\n",
    "* `lowqual_mbfc`\n",
    "\n",
    "Show the explained variance ratio. Then project the low quality news sharing dimensions to this new dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work in the same way for the political orientation, getting a single PCA component, `pc1_politics`, for the variables:\n",
    "\n",
    "* `politics_hashtag`\n",
    "* `politics_followed`\n",
    "* `politics_sites1`\n",
    "* `politics_sites2`\n",
    "\n",
    "Show the explained variance ratio and project the political orientation dimensions to this new dimension.\n",
    "\n",
    "Introduce a new variable, `extremity`, which is the absolute value of the PCA component you got."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also do the same for `log_num_followers`, `log_num_friends`, `log_num_fol`, producing `pc1_fol`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the harmful language variables, perform PCA for *three* components, `pc1_harmful_language`, `pc2_harmful_language`, `pc3_harmful_language`, on the winsorized data of:\n",
    "\n",
    "* `rewire_abuse`\n",
    "* `rewire_hate`\n",
    "* `rewire_profanity`\n",
    "* `rewire_violent`\n",
    "* `rewire_sexually_explicit`\n",
    "* `jigsaw_toxicity`\n",
    "* `jigsaw_severe_toxicity`\n",
    "* `jigsaw_idenity_attack`\n",
    "* `jigsaw_insult`\n",
    "* `jigsaw_profanity`\n",
    "* `jigsaw_threat`\n",
    "\n",
    "Why use three components instead of one in this case? Try to interpret each of the principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to producing a single PCA component, `pc1_valence`, for the winsorized data of the valence variables:\n",
    "\n",
    "* `valence_neg`\n",
    "* `valence_neu`\n",
    "* `valence_pos`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, normalize the independent variables by taking their z-scores. You will use the following z-scored independent variables (winsorized as stated above):\n",
    "\n",
    "* `pc1_politics`\n",
    "* `pc1_misinfo`\n",
    "* `pc1_fol`,\n",
    "* `pc1_harmful_language`\n",
    "* `pc2_harmful_language`\n",
    "* `pc3_harmful_language`\n",
    "* `pc1_valence`\n",
    "* `tweets_in_2wk`\n",
    "* `botsentinel_score`\n",
    "* `extremity`\n",
    "* `w_moral_outrage`\n",
    "* `liwc_political`\n",
    "* `log_freq_pr_1h`\n",
    "* `log_repeated_tweet_count`\n",
    "* `barbera_std`\n",
    "* `politics_sites1_std`\n",
    "* `politics_sites2_ideo_std`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carry out a probit regression to predict suspension.\n",
    "\n",
    "Before going on to interpret your results, perform the [Bonferroni correction](https://en.wikipedia.org/wiki/Bonferroni_correction) and the [Holm-Bonferroni correction](https://en.wikipedia.org/wiki/Holm%E2%80%93Bonferroni_method) correction. The purpose of both of these tests is to reduce the likelihood of false positives (Type I errors) when conducting multiple statistical tests.\n",
    "\n",
    "In the Bonferroni correction, a hypothesis is rejected with an ajustment to the significance level $\\alpha$:\n",
    "\n",
    "$$ p < \\frac{\\alpha}{m} $$\n",
    "\n",
    "which means that the $p$ values are adjusted by:\n",
    "\n",
    "$$ p' = p \\times m $$\n",
    "\n",
    "where $m$ is the number of tests.\n",
    "\n",
    "The Bonferroni-Holm method is less conservative compared to Bonferroni. It sorts the $p$-values in ascending order and compares them to less stringent thresholds:\n",
    "\n",
    "$$ p_i \\le \\frac{\\alpha}{m - i + 1} $$ \n",
    "\n",
    "where $i$ is the $i$-th smallest $p$-value. Starting with the smallest $p$-value, hypotheses are rejected sequentially until a $p$-value fails to meet the threshold. That means that the $p$ values are adjusted by:\n",
    "\n",
    "$$ \\widetilde{p}_{(i)}=\\max _{j\\leq i}\\left\\{(m-j+1)p_{(j)}\\right\\}_{1}, \\text{ where }p_{(j)}\\text{ is the $j$-th smallest $p$-value and }\\{x\\}_{1}\\equiv \\min(x,1). $$\n",
    "\n",
    "Holm-Bonferroni applies progressively smaller corrections as it moves through the sorted $p$-values, making it less conservative and less likely to fall into false negatives (Type II errors).\n",
    "\n",
    "Based on the results, do you think that political orientation influences suspension?\n",
    "\n",
    "Do the same analysis using logit regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "You must submit your assignment as a Jupyter notebook that will contain the full code and documentation of how you solved the questions, and all other necessary files. Your submission must be fully replicable: that is, somebody reading it must be able to do exactly what you did and obtain the same results.\n",
    "\n",
    "The documentation must be at the level where somebody that has some knowledge of Python can understand exactly what you are doing and why. Your output must be as user-friendly as possible. That means that your output tables should not include zillions of columns that are not needed for your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Honor Code\n",
    "\n",
    "You understand that this is an individual assignment, and as such you must carry it out alone. You may seek help on the Internet, on ChatGPT/Gemini/etc., by Googling or searching in StackOverflow for general questions pertaining to the use of Python and pandas libraries and idioms. However, it is not right to ask direct questions that relate to the assignment and where people will actually solve your problem by answering them. You may discuss with your colleagues in order to better understand the questions, if they are not clear enough, but you should not ask them to share their answers with you, or to help you by giving specific advice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
